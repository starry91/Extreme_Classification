{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "colab": {
      "name": "XML-AE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaqvccu_joNQ",
        "colab_type": "code",
        "outputId": "4b30ac3c-ad5e-43d9-a16b-757d7b812da3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "!pip install torchviz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.4.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP4qdctBjv4c",
        "colab_type": "code",
        "outputId": "08c40c42-d47f-4697-b805-567515c63b06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-05T06:57:33.748378Z",
          "start_time": "2020-03-05T06:57:33.734155Z"
        },
        "id": "BP2Gtjp_jCht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchsummary import summary\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import pandas as pd\n",
        "from torch import optim\n",
        "import numpy as np\n",
        "from torchviz import make_dot\n",
        "from scipy.io.arff import loadarff\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ejyznjvlPEv",
        "colab_type": "code",
        "outputId": "888c5363-80c9-4cd6-9781-498120940d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "!unrar x /content/drive/'My Drive'/mediamill.rar"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/My Drive/mediamill.rar\n",
            "\n",
            "\n",
            "Would you like to replace the existing file mediamill.arff\n",
            "55708920 bytes, modified on 2007-02-28 17:51\n",
            "with a new one\n",
            "55708920 bytes, modified on 2007-02-28 17:51\n",
            "\n",
            "[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit A\n",
            "\n",
            "Extracting  mediamill.arff                                               \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b  4%\b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b 16%\b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b 20%\b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b 30%\b\b\b\b 31%\b\b\b\b 32%\b\b\b\b 33%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b 42%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b 48%\b\b\b\b 49%\b\b\b\b\b  OK \n",
            "Extracting  mediamill.xml                                                \b\b\b\b 49%\b\b\b\b\b  OK \n",
            "Extracting  mediamill-train.arff                                         \b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b 64%\b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b 68%\b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b 75%\b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b 84%\b\b\b\b 85%\b\b\b\b\b  OK \n",
            "Extracting  mediamill-test.arff                                          \b\b\b\b 85%\b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 92%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b 95%\b\b\b\b 96%\b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X06-8TBAMii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(path2):\n",
        "  path = \"/content\"\n",
        "  raw_data = loadarff(path+path2)\n",
        "  df_data = pd.DataFrame(raw_data[0])\n",
        "  X_cols = df_data.columns[:120]\n",
        "  Y_cols = df_data.columns[120:]\n",
        "  X_data = df_data[X_cols]\n",
        "  Y_data = df_data[Y_cols]\n",
        "  for col in Y_data.columns:\n",
        "    Y_data[col] = Y_data[col].apply(lambda x: x.decode(\"utf-8\"))\n",
        "    Y_data[col] = Y_data[col].astype(int)\n",
        "  return X_data.values, Y_data.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9IU_XxnAmj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = \"/mediamill-train.arff\"\n",
        "test_path = \"/mediamill-test.arff\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WClR2xZwyCB8",
        "colab_type": "code",
        "outputId": "78503db5-c9cc-4f01-e870-99cdc743bef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "X_train, Y_train = get_data(train_path)\n",
        "X_test, Y_test = get_data(test_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-05T06:41:08.645519Z",
          "start_time": "2020-03-05T06:41:08.563838Z"
        },
        "id": "C-09RkXBjCjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class XML(nn.Module):\n",
        "    def calculateBowAndTfIdf(self, input):\n",
        "        return self.bow.transform(input), self.tfidf.transform(input)\n",
        "    \n",
        "    def train(self, input):\n",
        "        self.BoW = CountVectorizer(input)\n",
        "        self.TfIdf = TfidfVectorizer(input)\n",
        "    \n",
        "    def __init__(self, input_size, embedding_size, attention_layer_size,\n",
        "                 encoder_layer_size, hidden_layer_size, output_size, margin):\n",
        "        self.m = margin\n",
        "        ########## Feature Embedding\n",
        "        ### Embedding Layer\n",
        "        nn.Module.__init__(self)\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        ### Attention Module\n",
        "        self.attentionfc1 = nn.Linear( embedding_size,  attention_layer_size)\n",
        "        self.attentionfc2 = nn.Linear(attention_layer_size, embedding_size)\n",
        "        ### fully connected layer\n",
        "        self.featurefc1 = nn.Linear(embedding_size, hidden_layer_size)\n",
        "                                      \n",
        "        ########## encoder\n",
        "        self.encoderfc1 = nn.Linear(output_size, encoder_layer_size)\n",
        "        self.encoderfc2 = nn.Linear(encoder_layer_size, hidden_layer_size)\n",
        "        \n",
        "        ########## decoder\n",
        "        self.decoderfc1 = nn.Linear(hidden_layer_size, encoder_layer_size)\n",
        "        self.decoderfc2 = nn.Linear(encoder_layer_size, output_size)\n",
        "        \n",
        "    def reconstructingLoss(self, y_predicted, y_actual):\n",
        "        loss = 0\n",
        "        for i in range(y_predicted.shape[0]):\n",
        "          y_hat_n = y_predicted[i][y_actual[i]==0]\n",
        "          y_hat_p = y_predicted[i][y_actual[i]==1]\n",
        "          if(len(y_hat_p) == 0):\n",
        "            continue\n",
        "          y_p_min = torch.min(y_hat_p)\n",
        "          y_n_max = torch.max(y_hat_n)\n",
        "          loss1 = torch.sum(y_hat_n+self.m-y_p_min)\n",
        "          loss1[loss1 < 0] = 0\n",
        "          loss2 = torch.sum(-y_hat_p+self.m+y_n_max)\n",
        "          loss2[loss2 < 0] = 0\n",
        "          loss += (loss1+loss2)\n",
        "        return loss\n",
        "    \n",
        "    def hiddenLoss(self, x_hidden, y_hidden):\n",
        "        return torch.sum((x_hidden-y_hidden)**2)\n",
        "      \n",
        "    def train(self, X_train, Y_train, lr_=0.001, epochs=10, batch_size=256):\n",
        "      X_data_new = np.array([list(range(X_train.shape[1]))]*X_train.shape[0])\n",
        "      X_TfIdftensor =  torch.from_numpy(X_train)\n",
        "      X_data_tensor =  torch.from_numpy(X_data_new)\n",
        "      Y_data_tensor =  torch.from_numpy(Y_train)\n",
        "      criterion = self.loss\n",
        "      optimizer = optim.Adam(self.parameters(),lr=lr_)\n",
        "      # epochs = 10\n",
        "      # batch_size = 256 # or whatever\n",
        "      for i,e in enumerate(range(epochs)):\n",
        "          permutation = torch.randperm(X_data_tensor.size()[0])\n",
        "\n",
        "          for j in range(0,X_data_tensor.size()[0], batch_size):\n",
        "            indices = permutation[j:j+batch_size]\n",
        "            optimizer.zero_grad()\n",
        "            x_hidden, y_hidden, y_predicted = self.forward(X_data_tensor[indices], X_TfIdftensor[indices][:, :, None].type('torch.FloatTensor'), Y_data_tensor[indices].type('torch.FloatTensor'))\n",
        "            loss = criterion(x_hidden, y_hidden, y_predicted, Y_data_tensor[indices].type('torch.FloatTensor'))\n",
        "            loss.backward() # Backpropagation\n",
        "            optimizer.step() # Optimizer one step\n",
        "          print(f\"Epoch - {i+1}, Loss - {round(loss.item(),3)}\")  # Print loss\n",
        "\n",
        "    def f_x(self, bow, tfidf):\n",
        "        word_embedding = self.embedding(bow)\n",
        "        #print(\"word_embedding_shape: \", word_embedding.shape)\n",
        "        #print(\"tfidf:\", tfidf.shape)\n",
        "        word_embedding = tfidf * word_embedding\n",
        "        #print(\"tfidf * word_embedding: \", word_embedding.shape)\n",
        "        attention_embedding = word_embedding\n",
        "        attention_embedding = torch.relu(self.attentionfc1(attention_embedding))\n",
        "        #print(\"Attention after fc1: \", attention_embedding.shape)\n",
        "        attention_embedding = torch.relu(self.attentionfc2(attention_embedding))\n",
        "        #print(\"Attention after fc2: \", attention_embedding.shape)\n",
        "        word_embedding = attention_embedding * word_embedding\n",
        "        #print(\"Attention before pooling: \", word_embedding.shape)\n",
        "        ###word_embedding - max pooling\n",
        "        #print(\"word_embedding_shape: \", word_embedding.shape, \" \", word_embedding.type())\n",
        "        word_embedding = word_embedding.mean(1)\n",
        "        #print(\"Attention after pooling: \", word_embedding.shape)\n",
        "        x_hidden = torch.relu(self.featurefc1(word_embedding))\n",
        "        return x_hidden\n",
        "    \n",
        "    def e_y(self, labels):\n",
        "        y_hidden = torch.relu(self.encoderfc1(labels))\n",
        "        y_hidden = torch.relu(self.encoderfc2(y_hidden))\n",
        "        return y_hidden\n",
        "    \n",
        "    def d_y(self, y_hidden):\n",
        "        y_predicted = torch.relu(self.decoderfc1(y_hidden))\n",
        "        y_predicted = torch.sigmoid(self.decoderfc2(y_predicted))\n",
        "        return y_predicted\n",
        "\n",
        "    def forward(self, bow, tfidf, labels):\n",
        "        x_hidden = self.f_x(bow, tfidf)\n",
        "        y_hidden = self.e_y(labels)\n",
        "        y_predicted = self.d_y(y_hidden)\n",
        "        return x_hidden, y_hidden, y_predicted\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        X_data_new = np.array([list(range(X_test.shape[1]))]*X_test.shape[0])\n",
        "        tfidf =  torch.from_numpy(X_test)\n",
        "        tfidf = tfidf[:, :, None].type('torch.FloatTensor')\n",
        "        bow =  torch.from_numpy(X_data_new)\n",
        "        x_hidden = self.f_x(bow, tfidf)\n",
        "        y_predicted = self.d_y(x_hidden)\n",
        "        return y_predicted.cpu().detach().numpy()\n",
        "\n",
        "    def loss(self, x_hidden, y_hidden, y_predicted, y_actual, lamda = 1):\n",
        "        loss_hidden = self.hiddenLoss(x_hidden, y_hidden)\n",
        "        loss_ae = self.reconstructingLoss(y_predicted, y_actual)\n",
        "        return loss_hidden+lamda*loss_ae\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPZhhmN_zd9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def p_k(y_predicted, y_actual, k):\n",
        "  res = 0\n",
        "  for i in range(len(y_predicted)):\n",
        "    indices = y_predicted[i].argsort()[-k:][::-1]\n",
        "    res += (y_actual[i][indices].sum())/k\n",
        "  return res/len(y_predicted)\n",
        "\n",
        "def dcg_k(y_predicted, y_actual, k):\n",
        "  logger = lambda t: 1/math.log(1+t,2)\n",
        "  logger = np.vectorize(logger)\n",
        "  l = np.arange(1,1+y_predicted.shape[1])\n",
        "  l = logger(l)\n",
        "  res = np.zeros(y_predicted.shape[0])\n",
        "  for i in range(len(y_predicted)):\n",
        "    indices = y_predicted[i].argsort()[-k:][::-1]\n",
        "    temp = l*y_actual[i]\n",
        "    res[i] = temp[indices].sum()\n",
        "  return res\n",
        "\n",
        "def n_k(y_predicted, y_actual, k):\n",
        "  dcg_k_list = dcg_k(y_predicted, y_actual, k)\n",
        "  logger = lambda t: 1/math.log(1+t,2)\n",
        "  logger = np.vectorize(logger)\n",
        "  res = 0\n",
        "  for i in range(len(y_predicted)):\n",
        "    lim = y_actual[i].sum()\n",
        "    if(lim == 0):\n",
        "      continue\n",
        "    l = np.arange(1,1+min(lim,k))\n",
        "    l = logger(l)\n",
        "    deno = l.sum()\n",
        "    res += dcg_k_list[i]/deno\n",
        "  return res/y_predicted.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-05T06:41:08.884779Z",
          "start_time": "2020-03-05T06:41:08.868401Z"
        },
        "id": "v6EAQ-DKjCjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "document = \"Hey there delilah whats it like in new york city I am thousand miles away but tonight you look so pretty yes you do hey there delilah don't you worry about the distance I am right there if you get lonenly give this song another listen\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-05T06:41:09.417574Z",
          "start_time": "2020-03-05T06:41:09.387412Z"
        },
        "scrolled": true,
        "id": "KVoopoBAjCjU",
        "colab_type": "code",
        "outputId": "5e069104-56c3-4ea4-d7c2-00ece4dbcdba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "count_vec = CountVectorizer()\n",
        "count_occurs = count_vec.fit_transform([document])\n",
        "count_occur_df = pd.DataFrame(\n",
        "    (count, word) for word, count in\n",
        "     zip(count_occurs.toarray().tolist()[0], \n",
        "    count_vec.get_feature_names()))\n",
        "count_occur_df.columns = ['Word', 'Count']\n",
        "count_occur_df.sort_values('Count', ascending=False, inplace=True)\n",
        "print(count_occur_df.shape)\n",
        "count_occur_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(36, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>you</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>there</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>delilah</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>hey</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>am</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Word  Count\n",
              "35      you      4\n",
              "27    there      3\n",
              "6   delilah      2\n",
              "12      hey      2\n",
              "1        am      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-05T06:41:10.074598Z",
          "start_time": "2020-03-05T06:41:10.025149Z"
        },
        "id": "uvR6vVOkjCjh",
        "colab_type": "code",
        "outputId": "3f105536-59de-4584-d20d-20f1cdf5e0ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "tfidf_vec = TfidfVectorizer()\n",
        "tfidf_count_occurs = tfidf_vec.fit_transform([document])\n",
        "tfidf_count_occur_df = pd.DataFrame(\n",
        "    (count, word) for word, count in zip(\n",
        "    tfidf_count_occurs.toarray().tolist()[0],   \n",
        "    tfidf_vec.get_feature_names()))\n",
        "tfidf_count_occur_df.columns = ['Word', 'Count']\n",
        "tfidf_count_occur_df.sort_values('Count', ascending=False, inplace=True)\n",
        "tfidf_count_occur_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>you</td>\n",
              "      <td>0.485071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>there</td>\n",
              "      <td>0.363803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>delilah</td>\n",
              "      <td>0.242536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>hey</td>\n",
              "      <td>0.242536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>am</td>\n",
              "      <td>0.242536</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Word     Count\n",
              "35      you  0.485071\n",
              "27    there  0.363803\n",
              "6   delilah  0.242536\n",
              "12      hey  0.242536\n",
              "1        am  0.242536"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNSKYQatjCkM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_dot(y_hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv_9qqmujCkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_dot(y_predicted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVafYeQVjCkZ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "make_dot(x_hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSNrxIA7jCk2",
        "colab_type": "code",
        "outputId": "24866e99-bbff-4fd2-a6d5-d17a6a6568f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "model = XML(input_size=X_train.shape[1], embedding_size=100, attention_layer_size=25,\n",
        "                encoder_layer_size=120, hidden_layer_size=100,output_size=Y_train.shape[1], margin=0.8)\n",
        "model.train(X_train, Y_train, lr_ = 0.001, epochs=10, batch_size=256)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch - 1, Loss - 315.224\n",
            "Epoch - 2, Loss - 160.493\n",
            "Epoch - 3, Loss - 87.947\n",
            "Epoch - 4, Loss - 113.275\n",
            "Epoch - 5, Loss - 166.713\n",
            "Epoch - 6, Loss - 66.215\n",
            "Epoch - 7, Loss - 72.662\n",
            "Epoch - 8, Loss - 85.233\n",
            "Epoch - 9, Loss - 169.967\n",
            "Epoch - 10, Loss - 72.585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78djLmcm9Mjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGOHwHbODfVp",
        "colab_type": "code",
        "outputId": "ba6a6374-0d57-4c51-a092-7c1a6729d8d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "p_k(y_pred, Y_test, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7587114759176088"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgPKMcZNAm0X",
        "colab_type": "code",
        "outputId": "71e2f130-e9a6-4e7b-d301-8101078501ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_k(y_pred, Y_test, 3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15359621248699956"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUlwVduCEemB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}